## Overview
The goal of this homework is to explore the use of MapReduce and Spark

The main file relies on datasets not provided in this Github. They can be obtained from 
https://raw.githubusercontent.com/mosesyhc/de300-2025sp-class/refs/heads/main/agnews_clean.csv
https://raw.githubusercontent.com/mosesyhc/de300-2025sp-class/refs/heads/main/w.csv
https://raw.githubusercontent.com/mosesyhc/de300-2025sp-class/refs/heads/main/bias.csv
https://raw.githubusercontent.com/mosesyhc/de300-2025sp-class/refs/heads/main/data_for_svm.csv

## Files Included
- 'DE300_HW3.ipynb' - main notebook file
- 'Dockerfile' - used to build Docker image

## Overview
1. TF-IDF
   - Computes raw Term Frequencies (TF), Document Frequencies (DF), Inverse Document Frequencies (IDF), and normalized TF–IDF scores
2. SVM hinge‐loss objective
   - Computed full regularized SVM loss
   
