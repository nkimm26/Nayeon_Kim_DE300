{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Homework 3: MapReduce and Spark**"
      ],
      "metadata": {
        "id": "w2Ok8dOPLzGj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. tf-idf definition"
      ],
      "metadata": {
        "id": "pfAmNUUzL2AU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92RY_Q4WLfQi",
        "outputId": "4ccc0a3e-8535-426d-cd34-e13914824224"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 33.2M  100 33.2M    0     0  58.2M      0 --:--:-- --:--:-- --:--:-- 58.1M\n"
          ]
        }
      ],
      "source": [
        "!curl https://raw.githubusercontent.com/mosesyhc/de300-2025sp-class/refs/heads/main/agnews_clean.csv -O"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir dataset\n",
        "!mv agnews_clean.csv dataset/"
      ],
      "metadata": {
        "id": "lOEWeF65MD4W"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize Spark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = (SparkSession.builder\n",
        "         .master(\"local[*]\")\n",
        "         .appName(\"AG news\")\n",
        "         .getOrCreate()\n",
        "        )\n",
        "\n",
        "agnews = spark.read.csv(\"dataset/agnews_clean.csv\", inferSchema=True, header=True)\n",
        "\n",
        "# turning the second column from a string to an array\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.types import ArrayType, StringType\n",
        "agnews = agnews.withColumn('filtered', F.from_json('filtered', ArrayType(StringType())))"
      ],
      "metadata": {
        "id": "ziSglbQ7L4dX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# each row contains the document id and a list of filtered words\n",
        "agnews.show(5, truncate=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wB82Z7ueMkE7",
        "outputId": "f206e950-5dd3-422c-cbc1-f9f2edc405cd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------------------------------+\n",
            "|_c0|                      filtered|\n",
            "+---+------------------------------+\n",
            "|  0|[wall, st, bears, claw, bac...|\n",
            "|  1|[carlyle, looks, toward, co...|\n",
            "|  2|[oil, economy, cloud, stock...|\n",
            "|  3|[iraq, halts, oil, exports,...|\n",
            "|  4|[oil, prices, soar, time, r...|\n",
            "+---+------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. tf-idf definition"
      ],
      "metadata": {
        "id": "uE_lVLj6MzYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.types import ArrayType, StringType\n",
        "from collections import defaultdict\n",
        "\n",
        "# pull \"filtered\" column and convert to rdd\n",
        "docs_rdd = (agnews.select(\"filtered\")\n",
        "            .rdd\n",
        "            .zipWithIndex()\n",
        "            .map(lambda rf: (rf[1], rf[0][0]))\n",
        "           )"
      ],
      "metadata": {
        "id": "-ul-RKV2Mz_m"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### mapping functions\n",
        "\n",
        "# returns ((doc_id, term),1) for every occurence of each term in document\n",
        "def map_phase_tf(document):\n",
        "    doc_id, terms = document\n",
        "    for t in terms:\n",
        "        yield ((doc_id, t), 1)\n",
        "\n",
        "# returns number of terms in document\n",
        "def map_phase_doc_length(document):\n",
        "    doc_id, terms = document\n",
        "    yield (doc_id, len(terms))\n",
        "\n",
        "# returns (term, 1) once per unique term in document\n",
        "def map_phase_df(document):\n",
        "    _, terms = document\n",
        "    for t in set(terms):\n",
        "        yield (t, 1)"
      ],
      "metadata": {
        "id": "JTEorCc_M5gD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shuffle and sort phase: appends each value into list for corresponding key\n",
        "def shuffle_and_sort(pairs):\n",
        "    grouped = defaultdict(list)\n",
        "    for key, values in pairs:\n",
        "        grouped[key].append(values)\n",
        "    return grouped"
      ],
      "metadata": {
        "id": "uHY-hc73M7Z9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reduce phase: sums up list of values for each key\n",
        "def reduce_phase(shuffled_data):\n",
        "    for key, values in shuffled_data.items():\n",
        "        yield (key, sum(values))"
      ],
      "metadata": {
        "id": "4wVgFKDWM8_w"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tf phase\n",
        "mapped_tf = docs_rdd.flatMap(map_phase_tf).collect()\n",
        "shuffled_tf = shuffle_and_sort(mapped_tf)\n",
        "reduced_tf = dict(reduce_phase(shuffled_tf))\n",
        "\n",
        "# document length\n",
        "mapped_len = docs_rdd.flatMap(map_phase_doc_length).collect()\n",
        "shuffled_len = shuffle_and_sort(mapped_len)\n",
        "reduced_len = dict(reduce_phase(shuffled_len))"
      ],
      "metadata": {
        "id": "h5-lDMRJM-9i"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "# normalizing term frequency\n",
        "tf_norm = {\n",
        "    (d,t):reduced_tf[(d,t)]/reduced_len[d]\n",
        "    for (d,t) in reduced_tf\n",
        "}\n",
        "\n",
        "# df phase\n",
        "mapped_df = docs_rdd.flatMap(map_phase_df).collect()\n",
        "shuffled_df = shuffle_and_sort(mapped_df)\n",
        "reduced_df = dict(reduce_phase(shuffled_df))\n",
        "\n",
        "# compyte idf for each term\n",
        "N = reduced_len.__len__()\n",
        "idf = {t:math.log(N/df) for t, df in reduced_df.items() }"
      ],
      "metadata": {
        "id": "lFTY9rinNMe_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### tf-idf\n",
        "\n",
        "# same terms grouped together for TF and IDF\n",
        "def map_phase_tf_join(doc_tf):\n",
        "    for (d,t),tfv in doc_tf.items():\n",
        "        yield (t,(\"TF\", d, tfv))\n",
        "\n",
        "def map_phase_idf_join(idf_dict):\n",
        "    for t,idfv in idf_dict.items():\n",
        "        yield (t,(\"IDF\", idfv))\n",
        "\n",
        "# computes TF-IDF multiplication\n",
        "def reduce_phase_tfidf(shuffled):\n",
        "    out = {}\n",
        "    for term, recs in shuffled.items():\n",
        "        idfv   = next(v for tag,*v in recs if tag==\"IDF\")[0]\n",
        "        for tag,*rest in recs:\n",
        "            if tag==\"TF\":\n",
        "                d,tfv = rest\n",
        "                out.setdefault(d,{})[term] = tfv * idfv\n",
        "    return out\n",
        "\n",
        "mapped_tf_j = list(map_phase_tf_join(tf_norm))\n",
        "mapped_idf_j = list(map_phase_idf_join(idf))\n",
        "shuffled_all = shuffle_and_sort(mapped_tf_j + mapped_idf_j)\n",
        "doc_tfidf = reduce_phase_tfidf(shuffled_all)"
      ],
      "metadata": {
        "id": "PNQCQj8gNTKM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the measures in a new column:"
      ],
      "metadata": {
        "id": "zpQiR82vNaTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# index agnews DF so each row gets the same 0-based doc_id\n",
        "agnews_indexed = (\n",
        "    agnews\n",
        "      .rdd\n",
        "      .zipWithIndex()\n",
        "      .map(lambda row_idx: (row_idx[1],) + tuple(row_idx[0]))\n",
        "      .toDF([\"doc_id\"] + agnews.columns)\n",
        ")"
      ],
      "metadata": {
        "id": "rNtTAwzrNa60"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import MapType, StringType, DoubleType # Import MapType and DoubleType\n",
        "\n",
        "# turn doc_tfidfinto Spark DF\n",
        "tfidf_rows = [\n",
        "    (doc_id, dict(doc_tfidf[doc_id]))\n",
        "    for doc_id in sorted(doc_tfidf.keys())\n",
        "]\n",
        "\n",
        "tfidf_df = (\n",
        "    spark.createDataFrame(tfidf_rows, [\"doc_id\", \"tfidf\"])\n",
        "         .withColumn(\"tfidf\",\n",
        "             F.col(\"tfidf\").cast(MapType(StringType(), DoubleType())))\n",
        ")"
      ],
      "metadata": {
        "id": "1U4GGbuGNh1U"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# join on doc_id\n",
        "agnews_with_tfidf = (\n",
        "    agnews_indexed\n",
        "      .join(tfidf_df, on=\"doc_id\", how=\"left\")\n",
        "      .drop(\"doc_id\")\n",
        ")\n",
        "\n",
        "# results\n",
        "agnews_with_tfidf.select(*agnews.columns, \"tfidf\").show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orzvntgmNzwD",
        "outputId": "f16d6244-f2f5-44a3-dd60-ff7bed06614d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|_c0  |filtered                                                                                                                                                                                                                                          |tfidf                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
            "+-----+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|0    |[wall, st, bears, claw, back, black, reuters, reuters, short, sellers, wall, street, dwindling, band, ultra, cynics, seeing, green]                                                                                                               |{st -> 0.2584728642725166, green -> 0.2877107940095433, black -> 0.2953171727366614, back -> 0.1892216338539946, bears -> 0.3372044607529448, cynics -> 0.563734318747707, ultra -> 0.4125512394225831, claw -> 0.499114829314058, reuters -> 0.24754017186645658, seeing -> 0.37743394553516213, street -> 0.24678348986493034, short -> 0.2773120373951269, band -> 0.3643421454792778, dwindling -> 0.4572386180709258, wall -> 0.5115985326511431, sellers -> 0.4468379768438066}                                                                                                                                                                                                                                                                                                                            |\n",
            "|1    |[carlyle, looks, toward, commercial, aerospace, reuters, reuters, private, investment, firm, carlyle, group, reputation, making, well, timed, occasionally, controversial, plays, defense, industry, quietly, placed, bets, another, part, market]|{private -> 0.1929050573011279, commercial -> 0.2057832028092643, placed -> 0.2284965552404658, part -> 0.16022031730914288, another -> 0.14507889141437585, reputation -> 0.2578098186776328, industry -> 0.15043731768548949, firm -> 0.15969712503706046, looks -> 0.1973537176743789, carlyle -> 0.7168306746824437, reuters -> 0.1650267812443044, defense -> 0.1751279339938823, occasionally -> 0.33274321954270536, controversial -> 0.20949395177306526, group -> 0.12468100563149095, making -> 0.1698717076460444, plays -> 0.22418048797172685, timed -> 0.324478643568105, investment -> 0.1890771769001148, bets -> 0.27861293130724324, market -> 0.13394932212703356, toward -> 0.1898997183872362, well -> 0.17053284421704767, aerospace -> 0.2581171817448437, quietly -> 0.25188254045524316}|\n",
            "|5    |[stocks, end, near, year, lows, reuters, reuters, stocks, ended, slightly, higher, friday, stayed, near, lows, year, oil, prices, surged, past, 36, 46, barrel, offsetting, positive, outlook, computer, maker, dell, inc, dell, o]               |{slightly -> 0.17676052180852383, 46 -> 0.2067185029184427, year -> 0.16492932872045324, stocks -> 0.22465153652572792, computer -> 0.12125053715366761, reuters -> 0.13924134667488183, oil -> 0.10431117828830276, surged -> 0.19042797405490253, friday -> 0.09051819454875144, end -> 0.1131018693698805, near -> 0.27092999101551124, prices -> 0.10854419401585633, inc -> 0.0925193542091254, barrel -> 0.15591601639460734, 36 -> 0.145856640464541, past -> 0.13552111644471848, maker -> 0.12413070044238618, positive -> 0.18127557126337487, lows -> 0.3919911697751357, o -> 0.1405921241478995, dell -> 0.35254772027561204, offsetting -> 0.27225416288029386, stayed -> 0.21601464260731984, ended -> 0.15552292945064294, outlook -> 0.15994024564769707, higher -> 0.13245598339561715}        |\n",
            "|71166|[morrison, sell, 114, safeway, stores, william, morrison, supermarkets, agreed, sell, 114, small, safeway, stores, distribution, centre, 260, 2, million, pounds, morrison, bought, stores, part, 3, billion, pound]                              |{small -> 0.17824327561715922, bought -> 0.22260935034639528, stores -> 0.5547523045922657, sell -> 0.3573487228385421, part -> 0.16022031730914288, centre -> 0.2307852855837423, 260 -> 0.3120167088784304, distribution -> 0.24051723929584967, pound -> 0.23686531422901486, 2 -> 0.11475866167470433, 3 -> 0.12647291408802364, 114 -> 0.584107751035921, million -> 0.12059253433765513, william -> 0.2554386387233761, billion -> 0.1384821662957166, pounds -> 0.2388291834256156, supermarkets -> 0.32267160045071863, safeway -> 0.6033879805369334, agreed -> 0.15421427266844476, morrison -> 0.9531779799494311}                                                                                                                                                                                    |\n",
            "|71168|[red, hat, users, urged, patch, trojan, fake, security, advisory, circulated, suggests, red, hat, 39, linux, distribution, users, download, install, malicious, code]                                                                             |{advisory -> 0.35553315279735404, code -> 0.2676709885148137, 39 -> 0.06626246236184721, trojan -> 0.33515032279036816, distribution -> 0.3092364505232353, circulated -> 0.43088597375193405, users -> 0.4146280532193081, urged -> 0.25546373983334403, patch -> 0.2978760685403857, red -> 0.39200493557135163, malicious -> 0.3252096173683629, suggests -> 0.30321828190839645, security -> 0.1661526995994275, download -> 0.2790238943931469, install -> 0.33867927384530727, linux -> 0.23299296468761296, hat -> 0.5790382712023375, fake -> 0.33515032279036816}                                                                                                                                                                                                                                       |\n",
            "+-----+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print first 5 documents\n",
        "for d in sorted(doc_tfidf)[:5]:\n",
        "    print(f\"Document {d}:\")\n",
        "    for term,score in sorted(doc_tfidf[d].items(), key=lambda x:-x[1])[:10]:\n",
        "        print(f\"{term:15s}{score: }\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWXFS8GnN9CJ",
        "outputId": "c7b8b8f8-5a97-430d-a337-dc825dbc39fa"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document 0:\n",
            "cynics          0.563734318747707\n",
            "wall            0.5115985326511431\n",
            "claw            0.499114829314058\n",
            "dwindling       0.4572386180709258\n",
            "sellers         0.4468379768438066\n",
            "ultra           0.4125512394225831\n",
            "seeing          0.37743394553516213\n",
            "band            0.3643421454792778\n",
            "bears           0.3372044607529448\n",
            "black           0.2953171727366614\n",
            "\n",
            "Document 1:\n",
            "carlyle         0.7168306746824437\n",
            "occasionally    0.33274321954270536\n",
            "timed           0.324478643568105\n",
            "bets            0.27861293130724324\n",
            "aerospace       0.2581171817448437\n",
            "reputation      0.2578098186776328\n",
            "quietly         0.25188254045524316\n",
            "placed          0.2284965552404658\n",
            "plays           0.22418048797172685\n",
            "controversial   0.20949395177306526\n",
            "\n",
            "Document 2:\n",
            "outlook         0.4265073217271922\n",
            "doldrums        0.3770252270329423\n",
            "economy         0.3721400726458204\n",
            "depth           0.31343954772064864\n",
            "hang            0.30475018305843793\n",
            "cloud           0.295159450642955\n",
            "soaring         0.2596334462817101\n",
            "plus            0.24449073714833106\n",
            "worries         0.23009353850726894\n",
            "summer          0.22694739048609625\n",
            "\n",
            "Document 3:\n",
            "pipeline        0.4720829409342409\n",
            "main            0.36492623402353547\n",
            "oil             0.35763832555989516\n",
            "southern        0.336553609483104\n",
            "flows           0.2774168429760197\n",
            "halts           0.27365396741681164\n",
            "halted          0.2557691357056513\n",
            "export          0.23862435123782139\n",
            "iraq            0.23809526243476142\n",
            "infrastructure  0.22959926718225876\n",
            "\n",
            "Document 4:\n",
            "menace          0.5747440955975784\n",
            "tearaway        0.3918885216630942\n",
            "straining       0.2904044404056468\n",
            "toppling        0.27964532733021175\n",
            "wallets         0.2665151844733088\n",
            "posing          0.2589223867776184\n",
            "afp             0.2559170042376607\n",
            "prices          0.23156094723382684\n",
            "soar            0.2306791247647116\n",
            "oil             0.22253051368171256\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. SVM objective function"
      ],
      "metadata": {
        "id": "pS2O1wslOASN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://raw.githubusercontent.com/mosesyhc/de300-2025sp-class/refs/heads/main/w.csv -O\n",
        "!curl https://raw.githubusercontent.com/mosesyhc/de300-2025sp-class/refs/heads/main/bias.csv -O\n",
        "!curl https://raw.githubusercontent.com/mosesyhc/de300-2025sp-class/refs/heads/main/data_for_svm.csv -O"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpdnyGiiODhS",
        "outputId": "4497e493-5113-48b3-c6c2-5ec5ebd2bdc8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1391  100  1391    0     0   9361      0 --:--:-- --:--:-- --:--:--  9398\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100    22  100    22    0     0    173      0 --:--:-- --:--:-- --:--:--   174\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 61.9M  100 61.9M    0     0  76.2M      0 --:--:-- --:--:-- --:--:-- 76.1M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# initialize Spark\n",
        "spark = (SparkSession.builder\n",
        "        .master(\"local[*]\")\n",
        "        .appName(\"SVM_Loss_Calc\")\n",
        "        .getOrCreate()\n",
        "        )\n",
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "UUYu3MOAOKYy"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load data into rdds\n",
        "data_df = spark.read.csv(\"data_for_svm.csv\", header=False, inferSchema=True)\n",
        "X = data_df.rdd.map(lambda row: [float(row[i]) for i in range(64)])\n",
        "y = data_df.rdd.map(lambda row: int(row[64]))"
      ],
      "metadata": {
        "id": "iFLvEonrOWtv"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load w and bias csvs\n",
        "w = [float(r[0]) for r in spark.read.csv(\"w.csv\", header=False, inferSchema=True).collect()]\n",
        "b = float(spark.read.csv(\"bias.csv\", header=False, inferSchema=True).collect()[0][0])"
      ],
      "metadata": {
        "id": "RBTVjDkBOdo8"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# max component of function\n",
        "def compute_max(x_vec, y_lbl, w, b):\n",
        "    margin = sum(w_i*x_i for w_i, x_i in zip(w, x_vec)) + b\n",
        "    return max(0.0, 1 - y_lbl * margin)"
      ],
      "metadata": {
        "id": "pg_qMpZSOuuy"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# svm function\n",
        "def loss_SVM(w, b, X, y, lmb=1.0):\n",
        "    # pair features & labels\n",
        "    xy_rdd = X.zip(y)\n",
        "    # map to individual losses\n",
        "    margin_loss_rdd = xy_rdd.map(lambda xy: compute_max(xy[0], xy[1], w, b))\n",
        "    total_max = margin_loss_rdd.sum()\n",
        "    n = X.count()\n",
        "    # compute L2-norm squared of weight vector\n",
        "    w_norm_sq = sum(w_i**2 for w_i in w)\n",
        "    return lmb*w_norm_sq + (1.0/n)*total_max"
      ],
      "metadata": {
        "id": "6NAm_gEGO98B"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute objective value of SVM\n",
        "svm_obj = loss_SVM(w, b, X, y, lmb=1.0)\n",
        "print(f\"SVM objective ({svm_obj:})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgCVYPuuPIMF",
        "outputId": "aab375b7-a8e1-492a-d4c4-f69b34e3ba50"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM objective (1.0000598582575095)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function to make prediction\n",
        "def predict(w, b, X):\n",
        "    return X.map(\n",
        "        lambda x_vec:\n",
        "            1 if (sum(w_i * x_i for w_i, x_i in zip(w, x_vec)) + b) >= 0\n",
        "              else -1\n",
        "    )"
      ],
      "metadata": {
        "id": "R2XAzJmhPLbA"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apply function and predict\n",
        "predictions_rdd = predict(w, b, X)\n",
        "predictions = predictions_rdd.collect()\n",
        "print(f\"Total predictions: {predictions_rdd.count()}\")\n",
        "print(\"First 20 predictions:\", predictions[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9Tkfve8Pxa0",
        "outputId": "5e27adef-82f3-4b44-c337-508ca33d5162"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total predictions: 400000\n",
            "First 20 predictions: [1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, 1, -1, -1, 1, -1, -1, 1, -1, -1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generative AI Disclosure:\n",
        "\n",
        "1) I used GAI to help resolve the errors I ran into throughout the homework\n",
        "\n",
        "2) I used ChatGPT\n",
        "\n",
        "3) I copied and pasted my error message into ChatGPT and asked \"how do I fix this error\""
      ],
      "metadata": {
        "id": "wSl2YciqQJNI"
      }
    }
  ]
}